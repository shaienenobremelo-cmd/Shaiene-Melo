{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "V5E1"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Nova se√ß√£o"
      ],
      "metadata": {
        "id": "7GDIIr2vNZdk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "_zyFLgg_22B_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Instalando o PySpark\n",
        "!apt-get -qq update\n",
        "!apt-get -qq install -y openjdk-17-jdk-headless\n",
        "!pip -q install -U pyspark[connect]==4.0.0\n",
        "\n",
        "print('‚úÖ PySpark instalado com sucesso!')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "lDo2hNkENEbJ",
        "outputId": "f953ded5-a89f-416d-9e68-b47a0a78d5ea"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "W: Skipping acquire of configured file 'main/source/Sources' as repository 'https://r2u.stat.illinois.edu/ubuntu jammy InRelease' does not seem to provide it (sources.list entry misspelt?)\n",
            "(Reading database ... 117540 files and directories currently installed.)\n",
            "Preparing to unpack .../openjdk-17-jdk-headless_17.0.18+8-1~22.04.1_amd64.deb ...\n",
            "Unpacking openjdk-17-jdk-headless:amd64 (17.0.18+8-1~22.04.1) over (17.0.17+10-1~22.04) ...\n",
            "Preparing to unpack .../openjdk-17-jre-headless_17.0.18+8-1~22.04.1_amd64.deb ...\n",
            "Unpacking openjdk-17-jre-headless:amd64 (17.0.18+8-1~22.04.1) over (17.0.17+10-1~22.04) ...\n",
            "Setting up openjdk-17-jre-headless:amd64 (17.0.18+8-1~22.04.1) ...\n",
            "Installing new version of config file /etc/java-17-openjdk/jfr/default.jfc ...\n",
            "Installing new version of config file /etc/java-17-openjdk/security/java.security ...\n",
            "Setting up openjdk-17-jdk-headless:amd64 (17.0.18+8-1~22.04.1) ...\n",
            "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m434.1/434.1 MB\u001b[0m \u001b[31m956.8 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m203.0/203.0 kB\u001b[0m \u001b[31m18.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for pyspark (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "‚úÖ PySpark instalado com sucesso!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql import SparkSession\n",
        "from pyspark.sql.functions import *\n",
        "\n",
        "# Criando uma SparkSession\n",
        "spark = SparkSession.builder \\\n",
        "    .master('local[*]') \\\n",
        "    .appName('PrevisaoVendasML') \\\n",
        "    .config('spark.driver.memory', '4g') \\\n",
        "    .getOrCreate()\n",
        "\n",
        "print('‚úÖ SparkSession criada com sucesso!')\n",
        "print(f'Spark vers√£o: {spark.version}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GcntwjxCNIQM",
        "outputId": "05866225-84a6-47c9-ce7a-0bd0983b03e8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ SparkSession criada com sucesso!\n",
            "Spark vers√£o: 4.0.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Instalar kagglehub\n",
        "!pip install -q kagglehub\n",
        "\n",
        "import kagglehub\n",
        "import os\n",
        "import glob\n",
        "\n",
        "# Download do dataset\n",
        "print('Baixando dataset do Kaggle...')\n",
        "path = kagglehub.dataset_download(\"olistbr/brazilian-ecommerce\")\n",
        "print(f'‚úÖ Dataset baixado em: {path}')\n",
        "\n",
        "# Listar arquivos\n",
        "files = sorted(glob.glob(path + \"/*.csv\"))\n",
        "print(f'\\nTotal de arquivos: {len(files)}')\n",
        "for f in files:\n",
        "    filename = os.path.basename(f)\n",
        "    size_mb = os.path.getsize(f) / (1024 * 1024)\n",
        "    print(f'  - {filename} ({size_mb:.2f} MB)')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ekTvZrCdNgiz",
        "outputId": "165daa3f-0bb6-4560-da1e-fc8334fdbe3e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Baixando dataset do Kaggle...\n",
            "Using Colab cache for faster access to the 'brazilian-ecommerce' dataset.\n",
            "‚úÖ Dataset baixado em: /kaggle/input/brazilian-ecommerce\n",
            "\n",
            "Total de arquivos: 9\n",
            "  - olist_customers_dataset.csv (8.62 MB)\n",
            "  - olist_geolocation_dataset.csv (58.44 MB)\n",
            "  - olist_order_items_dataset.csv (14.72 MB)\n",
            "  - olist_order_payments_dataset.csv (5.51 MB)\n",
            "  - olist_order_reviews_dataset.csv (13.78 MB)\n",
            "  - olist_orders_dataset.csv (16.84 MB)\n",
            "  - olist_products_dataset.csv (2.27 MB)\n",
            "  - olist_sellers_dataset.csv (0.17 MB)\n",
            "  - product_category_name_translation.csv (0.00 MB)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql import functions as F\n",
        "\n",
        "# Carregar datasets necess√°rios\n",
        "data_files = {}\n",
        "for f in glob.glob(path + '/*.csv'): # Use a vari√°vel 'path' que cont√©m o caminho do Kaggle\n",
        "    name = os.path.basename(f).replace('.csv', '')\n",
        "    data_files[name] = spark.read.csv(f, header=True, inferSchema=True, multiLine=True, escape='\"')\n",
        "    print(f'‚úì {name}: {data_files[name].count()} linhas')\n",
        "\n",
        "# Extrair datasets principais\n",
        "orders = data_files['olist_orders_dataset']\n",
        "items = data_files['olist_order_items_dataset']\n",
        "products = data_files['olist_products_dataset']\n",
        "customers = data_files['olist_customers_dataset']\n",
        "translations = data_files['product_category_name_translation']\n",
        "\n",
        "print('\\n‚úÖ Datasets carregados com sucesso!')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "idYu_asMNhQ2",
        "outputId": "6a94aa66-3d1f-491e-cbbd-b3355727392a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úì olist_customers_dataset: 99441 linhas\n",
            "‚úì olist_sellers_dataset: 3095 linhas\n",
            "‚úì olist_order_reviews_dataset: 99224 linhas\n",
            "‚úì olist_order_items_dataset: 112650 linhas\n",
            "‚úì olist_products_dataset: 32951 linhas\n",
            "‚úì olist_geolocation_dataset: 1000163 linhas\n",
            "‚úì product_category_name_translation: 71 linhas\n",
            "‚úì olist_orders_dataset: 99441 linhas\n",
            "‚úì olist_order_payments_dataset: 103886 linhas\n",
            "\n",
            "‚úÖ Datasets carregados com sucesso!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Converter timestamps\n",
        "orders_ts = (\n",
        "    orders\n",
        "    .withColumn(\"purchase_ts\", F.to_timestamp(\"order_purchase_timestamp\"))\n",
        "    .filter(F.col(\"purchase_ts\").isNotNull())\n",
        ")\n",
        "\n",
        "# Extrair features temporais\n",
        "orders_ts = (\n",
        "    orders_ts\n",
        "    .withColumn(\"year\", F.year(\"purchase_ts\"))\n",
        "    .withColumn(\"month\", F.month(\"purchase_ts\"))\n",
        "    .withColumn(\"day_of_week\", F.dayofweek(\"purchase_ts\"))\n",
        "    .withColumn(\"quarter\", F.quarter(\"purchase_ts\"))\n",
        "    .withColumn(\"week_of_year\", F.weekofyear(\"purchase_ts\"))\n",
        ")\n",
        "\n",
        "print(\"‚úÖ Features temporais criadas\")\n",
        "orders_ts.select(\"order_id\", \"year\", \"month\", \"quarter\", \"day_of_week\").show(5)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t8LpclRaNiSS",
        "outputId": "83e922c7-275a-4b7b-9b8f-4c5c8f28f518"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Features temporais criadas\n",
            "+--------------------+----+-----+-------+-----------+\n",
            "|            order_id|year|month|quarter|day_of_week|\n",
            "+--------------------+----+-----+-------+-----------+\n",
            "|e481f51cbdc54678b...|2017|   10|      4|          2|\n",
            "|53cdb2fc8bc7dce0b...|2018|    7|      3|          3|\n",
            "|47770eb9100c2d0c4...|2018|    8|      3|          4|\n",
            "|949d5b44dbf5de918...|2017|   11|      4|          7|\n",
            "|ad21c59c0840e6cb8...|2018|    2|      1|          3|\n",
            "+--------------------+----+-----+-------+-----------+\n",
            "only showing top 5 rows\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Juntar orders com items\n",
        "df_base = (\n",
        "    orders_ts\n",
        "    .join(items, on=\"order_id\", how=\"inner\")\n",
        "    .join(products, on=\"product_id\", how=\"left\")\n",
        "    .join(customers, on=\"customer_id\", how=\"left\")\n",
        "    .join(translations, on=\"product_category_name\", how=\"left\")\n",
        ")\n",
        "\n",
        "# Selecionar colunas relevantes\n",
        "df_sales = df_base.select(\n",
        "    \"order_id\",\n",
        "    \"year\",\n",
        "    \"month\",\n",
        "    \"day_of_week\",\n",
        "    \"quarter\",\n",
        "    \"week_of_year\",\n",
        "    \"customer_state\",\n",
        "    F.col(\"product_category_name_english\").alias(\"category\"),\n",
        "    \"price\",\n",
        "    \"freight_value\",\n",
        "    \"order_item_id\"\n",
        ")\n",
        "\n",
        "print(f\"‚úÖ Base preparada: {df_sales.count()} registros\")\n",
        "df_sales.show(5)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YH_CFSp1Nmdo",
        "outputId": "b14e3273-cff5-4fcb-8488-54e2de7cbcb1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Base preparada: 112650 registros\n",
            "+--------------------+----+-----+-----------+-------+------------+--------------+---------------+-----+-------------+-------------+\n",
            "|            order_id|year|month|day_of_week|quarter|week_of_year|customer_state|       category|price|freight_value|order_item_id|\n",
            "+--------------------+----+-----+-----------+-------+------------+--------------+---------------+-----+-------------+-------------+\n",
            "|00310b0c75bb13015...|2018|    8|          4|      3|          33|            MG|     housewares| 39.9|        15.38|            1|\n",
            "|0032d07457ae9c806...|2018|    3|          7|      1|          10|            RJ|     housewares|159.0|        27.19|            1|\n",
            "|0045e3085f083f0f3...|2017|    8|          5|      3|          32|            SP|  health_beauty|116.9|        13.84|            1|\n",
            "|0079bca8e89bd52fd...|2018|    5|          5|      2|          18|            SP| sports_leisure| 49.9|         7.39|            1|\n",
            "|007ff0b0f79be782f...|2018|    2|          7|      1|           5|            MG|furniture_decor| 39.0|        16.11|            1|\n",
            "+--------------------+----+-----+-----------+-------+------------+--------------+---------------+-----+-------------+-------------+\n",
            "only showing top 5 rows\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Agregar por ano, m√™s, estado e categoria\n",
        "sales_agg = (\n",
        "    df_sales\n",
        "    .groupBy(\"year\", \"month\", \"customer_state\", \"category\")\n",
        "    .agg(\n",
        "        F.sum(\"price\").alias(\"total_sales\"),\n",
        "        F.count(\"order_id\").alias(\"num_orders\"),\n",
        "        F.avg(\"price\").alias(\"avg_price\"),\n",
        "        F.sum(\"freight_value\").alias(\"total_freight\"),\n",
        "        F.countDistinct(\"order_id\").alias(\"unique_orders\"),\n",
        "        F.avg(\"day_of_week\").alias(\"avg_day_of_week\")\n",
        "    )\n",
        "    .withColumnRenamed(\"customer_state\", \"state\")\n",
        ")\n",
        "\n",
        "print(f\"‚úÖ Agrega√ß√£o criada: {sales_agg.count()} registros\")\n",
        "sales_agg.show(5)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S_nMC2gXNomK",
        "outputId": "be7e13cb-5d27-4fa3-d072-b45935b29808"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Agrega√ß√£o criada: 11808 registros\n",
            "+----+-----+-----+---------------+------------------+----------+------------------+-----------------+-------------+------------------+\n",
            "|year|month|state|       category|       total_sales|num_orders|         avg_price|    total_freight|unique_orders|   avg_day_of_week|\n",
            "+----+-----+-----+---------------+------------------+----------+------------------+-----------------+-------------+------------------+\n",
            "|2017|   11|   RJ|     cool_stuff|           8169.49|        43|189.98813953488371|923.0599999999998|           43| 4.046511627906977|\n",
            "|2017|    2|   SP|furniture_decor|           9440.28|       118| 80.00237288135594|          2000.15|           98| 3.805084745762712|\n",
            "|2017|   10|   PI|   home_confort|              89.9|         1|              89.9|            38.18|            1|               5.0|\n",
            "|2018|    8|   MG|     stationery|            2056.9|        17|120.99411764705883|           371.45|           17|3.4705882352941178|\n",
            "|2018|    8|   SP|      telephony|12197.869999999999|       103|118.42592233009708|          1309.58|           96|               4.0|\n",
            "+----+-----+-----+---------------+------------------+----------+------------------+-----------------+-------------+------------------+\n",
            "only showing top 5 rows\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.window import Window\n",
        "\n",
        "# Criar window particionado por estado e categoria, ordenado por ano e m√™s\n",
        "window_spec = Window.partitionBy(\"state\", \"category\").orderBy(\"year\", \"month\")\n",
        "\n",
        "# Criar lag features\n",
        "sales_agg = (\n",
        "    sales_agg\n",
        "    .withColumn(\"sales_lag_1\", F.lag(\"total_sales\", 1).over(window_spec))\n",
        "    .withColumn(\"sales_lag_2\", F.lag(\"total_sales\", 2).over(window_spec))\n",
        "    .withColumn(\"sales_lag_3\", F.lag(\"total_sales\", 3).over(window_spec))\n",
        "    .withColumn(\"orders_lag_1\", F.lag(\"num_orders\", 1).over(window_spec))\n",
        "    .withColumn(\"orders_lag_2\", F.lag(\"num_orders\", 2).over(window_spec))\n",
        ")\n",
        "\n",
        "# Remover linhas com nulls criados pelo lag\n",
        "sales_agg = sales_agg.na.drop()\n",
        "\n",
        "print(f\"‚úÖ Lag features criadas: {sales_agg.count()} registros\")\n",
        "sales_agg.select(\"state\", \"category\", \"year\", \"month\", \"total_sales\", \"sales_lag_1\", \"sales_lag_2\").show(5)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SiZQdyIKNtL4",
        "outputId": "a2169aad-bce9-46d8-ce91-4d0c4aa4387a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Lag features criadas: 8085 registros\n",
            "+-----+--------------------+----+-----+-----------+-----------+-----------+\n",
            "|state|            category|year|month|total_sales|sales_lag_1|sales_lag_2|\n",
            "+-----+--------------------+----+-----+-----------+-----------+-----------+\n",
            "|   AC|computers_accesso...|2017|   10|      51.98|       31.9|      809.1|\n",
            "|   AC|computers_accesso...|2018|    3|       27.9|      51.98|       31.9|\n",
            "|   AC|computers_accesso...|2018|    7|      289.0|       27.9|      51.98|\n",
            "|   AC|         electronics|2018|    2|      13.65|      239.0|      189.9|\n",
            "|   AC|     furniture_decor|2018|    1|      88.34|      250.0|      179.9|\n",
            "+-----+--------------------+----+-----+-----------+-----------+-----------+\n",
            "only showing top 5 rows\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# M√©dia m√≥vel de 3 meses\n",
        "window_rolling = Window.partitionBy(\"state\", \"category\").orderBy(\"year\", \"month\").rowsBetween(-2, 0)\n",
        "\n",
        "sales_agg = (\n",
        "    sales_agg\n",
        "    .withColumn(\"sales_rolling_mean_3\", F.avg(\"total_sales\").over(window_rolling))\n",
        "    .withColumn(\"orders_rolling_mean_3\", F.avg(\"num_orders\").over(window_rolling))\n",
        ")\n",
        "\n",
        "print(\"‚úÖ M√©dias m√≥veis criadas\")\n",
        "sales_agg.select(\"state\", \"category\", \"total_sales\", \"sales_rolling_mean_3\").show(5)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nWSA_DvZNuUa",
        "outputId": "752c86e0-7a1d-44aa-aee5-c0c1174906af"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ M√©dias m√≥veis criadas\n",
            "+-----+--------------------+-----------+--------------------+\n",
            "|state|            category|total_sales|sales_rolling_mean_3|\n",
            "+-----+--------------------+-----------+--------------------+\n",
            "|   AC|computers_accesso...|      51.98|               51.98|\n",
            "|   AC|computers_accesso...|       27.9|               39.94|\n",
            "|   AC|computers_accesso...|      289.0|              122.96|\n",
            "|   AC|         electronics|      13.65|               13.65|\n",
            "|   AC|     furniture_decor|      88.34|               88.34|\n",
            "+-----+--------------------+-----------+--------------------+\n",
            "only showing top 5 rows\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.ml.feature import StringIndexer, VectorAssembler, StandardScaler\n",
        "\n",
        "# Definir features (removendo 'quarter' que n√£o est√° em sales_agg)\n",
        "feature_cols = [\n",
        "    \"year\", \"month\", \"avg_day_of_week\", # 'quarter' removido daqui\n",
        "    \"num_orders\", \"avg_price\", \"total_freight\", \"unique_orders\",\n",
        "    \"sales_lag_1\", \"sales_lag_2\", \"sales_lag_3\",\n",
        "    \"orders_lag_1\", \"orders_lag_2\",\n",
        "    \"sales_rolling_mean_3\", \"orders_rolling_mean_3\",\n",
        "    \"state_idx\", \"category_idx\"\n",
        "]\n",
        "\n",
        "# Indexar vari√°veis categ√≥ricas\n",
        "idx_state = StringIndexer(inputCol=\"state\", outputCol=\"state_idx\", handleInvalid=\"keep\")\n",
        "idx_category = StringIndexer(inputCol=\"category\", outputCol=\"category_idx\", handleInvalid=\"keep\")\n",
        "\n",
        "# Aplicar indexa√ß√£o\n",
        "sales_indexed = idx_state.fit(sales_agg).transform(sales_agg)\n",
        "sales_indexed = idx_category.fit(sales_indexed).transform(sales_indexed)\n",
        "\n",
        "# Assembler\n",
        "assembler = VectorAssembler(\n",
        "    inputCols=feature_cols,\n",
        "    outputCol=\"features_raw\",\n",
        "    handleInvalid=\"skip\"\n",
        ")\n",
        "\n",
        "# Scaler\n",
        "scaler = StandardScaler(inputCol=\"features_raw\", outputCol=\"features\")\n",
        "\n",
        "# Aplicar transforma√ß√µes\n",
        "sales_vec = assembler.transform(sales_indexed)\n",
        "sales_scaled = scaler.fit(sales_vec).transform(sales_vec)\n",
        "\n",
        "# Dataset final para ML\n",
        "df_ml = sales_scaled.select(\"features\", F.col(\"total_sales\").alias(\"label\"))\n",
        "\n",
        "# Split\n",
        "train, test = df_ml.randomSplit([0.8, 0.2], seed=42)\n",
        "\n",
        "print(f\"‚úÖ Dados preparados para ML\")\n",
        "print(f\"   Train: {train.count()} registros\")\n",
        "print(f\"   Test: {test.count()} registros\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zE4dhq87Nv3o",
        "outputId": "2ee67563-17d0-4c36-d0ea-35eb6ab3928d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Dados preparados para ML\n",
            "   Train: 6540 registros\n",
            "   Test: 1545 registros\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.ml.regression import LinearRegression, RandomForestRegressor, GBTRegressor, DecisionTreeRegressor\n",
        "from pyspark.ml.evaluation import RegressionEvaluator\n",
        "import pandas as pd\n",
        "\n",
        "# Definir modelos\n",
        "models = {\n",
        "    \"Linear Regression\": LinearRegression(featuresCol=\"features\", labelCol=\"label\"),\n",
        "    \"Decision Tree\": DecisionTreeRegressor(featuresCol=\"features\", labelCol=\"label\", seed=42),\n",
        "    \"Random Forest\": RandomForestRegressor(featuresCol=\"features\", labelCol=\"label\", seed=42, numTrees=50),\n",
        "    \"Gradient Boosting\": GBTRegressor(featuresCol=\"features\", labelCol=\"label\", seed=42, maxIter=50)\n",
        "}\n",
        "\n",
        "# Evaluator\n",
        "evaluator_r2 = RegressionEvaluator(labelCol=\"label\", predictionCol=\"prediction\", metricName=\"r2\")\n",
        "evaluator_rmse = RegressionEvaluator(labelCol=\"label\", predictionCol=\"prediction\", metricName=\"rmse\")\n",
        "\n",
        "# Treinar e avaliar cada modelo\n",
        "results_baseline = {}\n",
        "\n",
        "for name, model in models.items():\n",
        "    print(f\"\\nTreinando {name}...\")\n",
        "\n",
        "    # Treinar\n",
        "    trained_model = model.fit(train)\n",
        "\n",
        "    # Prever\n",
        "    predictions = trained_model.transform(test)\n",
        "\n",
        "    # Avaliar\n",
        "    r2 = evaluator_r2.evaluate(predictions)\n",
        "    rmse = evaluator_rmse.evaluate(predictions)\n",
        "\n",
        "    results_baseline[name] = {\"R¬≤\": r2, \"RMSE\": rmse}\n",
        "    print(f\"  R¬≤: {r2:.4f} | RMSE: {rmse:.2f}\")\n",
        "\n",
        "# Mostrar resultados\n",
        "results_df = pd.DataFrame(results_baseline).T.sort_values(\"R¬≤\", ascending=False)\n",
        "print(\"\\nüìä Compara√ß√£o de Modelos (Baseline):\")\n",
        "print(results_df)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LofWTUuvNxTb",
        "outputId": "925f668d-8fc3-4beb-81bb-ee09de68bde6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Treinando Linear Regression...\n",
            "  R¬≤: 0.9855 | RMSE: 357.09\n",
            "\n",
            "Treinando Decision Tree...\n",
            "  R¬≤: 0.9019 | RMSE: 929.14\n",
            "\n",
            "Treinando Random Forest...\n",
            "  R¬≤: 0.9051 | RMSE: 913.96\n",
            "\n",
            "Treinando Gradient Boosting...\n",
            "  R¬≤: 0.9322 | RMSE: 772.53\n",
            "\n",
            "üìä Compara√ß√£o de Modelos (Baseline):\n",
            "                         R¬≤        RMSE\n",
            "Linear Regression  0.985514  357.093578\n",
            "Gradient Boosting  0.932205  772.526898\n",
            "Random Forest      0.905109  913.957707\n",
            "Decision Tree      0.901930  929.140243\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.ml.tuning import ParamGridBuilder, CrossValidator\n",
        "\n",
        "# Escolher Random Forest\n",
        "rf = RandomForestRegressor(featuresCol=\"features\", labelCol=\"label\", seed=42)\n",
        "\n",
        "# Grid de hiperpar√¢metros (reduzido para economizar mem√≥ria)\n",
        "paramGrid = (\n",
        "    ParamGridBuilder()\n",
        "    .addGrid(rf.numTrees, [50, 100]) # Reduzindo as op√ß√µes de numTrees\n",
        "    .addGrid(rf.maxDepth, [5, 10])    # Reduzindo as op√ß√µes de maxDepth\n",
        "    .addGrid(rf.minInstancesPerNode, [5, 10]) # Reduzindo e aumentando o valor m√≠nimo\n",
        "    .build()\n",
        ")\n",
        "\n",
        "# CrossValidator (reduzido numFolds para economizar mem√≥ria)\n",
        "crossval = (\n",
        "    CrossValidator(\n",
        "        estimator=rf,\n",
        "        estimatorParamMaps=paramGrid,\n",
        "        evaluator=evaluator_r2,\n",
        "        numFolds=3, # Reduzindo o n√∫mero de folds para 3\n",
        "        seed=42\n",
        "    )\n",
        ")\n",
        "\n",
        "print(\"üîÑ Executando CrossValidation (pode demorar alguns minutos)...\")\n",
        "cv_model = crossval.fit(train)\n",
        "\n",
        "print(\"‚úÖ CrossValidation conclu√≠da!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZDAic74cNzl3",
        "outputId": "e7fed086-2852-4da1-ba69-676e6efc90be"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üîÑ Executando CrossValidation (pode demorar alguns minutos)...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Melhor modelo\n",
        "best_model = cv_model.bestModel\n",
        "\n",
        "# Prever no teste\n",
        "predictions_cv = best_model.transform(test)\n",
        "\n",
        "# Avaliar\n",
        "r2_cv = evaluator_r2.evaluate(predictions_cv)\n",
        "rmse_cv = evaluator_rmse.evaluate(predictions_cv)\n",
        "\n",
        "print(f\"\\nüéØ MELHOR MODELO (Random Forest com CrossValidation):\")\n",
        "print(f\"   N√∫mero de √Årvores: {best_model.getNumTrees}\")\n",
        "print(f\"   Profundidade M√°xima: {best_model.getMaxDepth()}\")\n",
        "print(f\"   Min Instances Per Node: {best_model.getMinInstancesPerNode()}\")\n",
        "print(f\"   R¬≤: {r2_cv:.4f}\")\n",
        "print(f\"   RMSE: {rmse_cv:.2f}\")\n",
        "\n",
        "# Mostrar algumas predi√ß√µes\n",
        "print(\"\\nüìä Exemplos de Predi√ß√µes:\")\n",
        "predictions_cv.select(\"label\", \"prediction\").show(10)\n"
      ],
      "metadata": {
        "id": "CqV880QGN0Fd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "\n",
        "# Converter para pandas\n",
        "pred_pd = predictions_cv.select(\"label\", \"prediction\").toPandas()\n",
        "\n",
        "# Gr√°fico de dispers√£o (Real vs Previsto)\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.scatter(pred_pd[\"label\"], pred_pd[\"prediction\"], alpha=0.5, s=10)\n",
        "plt.plot([pred_pd[\"label\"].min(), pred_pd[\"label\"].max()],\n",
        "         [pred_pd[\"label\"].min(), pred_pd[\"label\"].max()],\n",
        "         'r--', lw=2, label='Linha Ideal')\n",
        "plt.xlabel(\"Vendas Reais (R$)\")\n",
        "plt.ylabel(\"Vendas Previstas (R$)\")\n",
        "plt.title(f\"Previs√£o vs Real (R¬≤ = {r2_cv:.4f})\")\n",
        "plt.legend()\n",
        "plt.grid(True, alpha=0.3)\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Gr√°fico de res√≠duos\n",
        "pred_pd['residual'] = pred_pd['label'] - pred_pd['prediction']\n",
        "\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.scatter(pred_pd[\"prediction\"], pred_pd[\"residual\"], alpha=0.5, s=10)\n",
        "plt.axhline(y=0, color='r', linestyle='--', lw=2)\n",
        "plt.xlabel(\"Vendas Previstas (R$)\")\n",
        "plt.ylabel(\"Res√≠duos (Real - Previsto)\")\n",
        "plt.title(\"An√°lise de Res√≠duos\")\n",
        "plt.grid(True, alpha=0.3)\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "qgo4j9UVN6nU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Adicionar resultado do CV\n",
        "results_baseline[\"Random Forest (CV)\"] = {\"R¬≤\": r2_cv, \"RMSE\": rmse_cv}\n",
        "\n",
        "# Criar DataFrame\n",
        "results_final = pd.DataFrame(results_baseline).T.sort_values(\"R¬≤\", ascending=False)\n",
        "\n",
        "print(\"\\nüìä Resultados Finais - Compara√ß√£o de Modelos:\")\n",
        "print(results_final)\n",
        "\n",
        "# Gr√°fico de barras\n",
        "fig, axes = plt.subplots(1, 2, figsize=(14, 6))\n",
        "\n",
        "# R¬≤\n",
        "axes[0].barh(results_final.index, results_final[\"R¬≤\"], color='steelblue')\n",
        "axes[0].axvline(x=0.65, color='red', linestyle='--', label='Meta (0.65)')\n",
        "axes[0].set_xlabel(\"R¬≤\")\n",
        "axes[0].set_title(\"Compara√ß√£o de Modelos - R¬≤\")\n",
        "axes[0].legend()\n",
        "axes[0].grid(axis='x', alpha=0.3)\n",
        "\n",
        "# RMSE\n",
        "axes[1].barh(results_final.index, results_final[\"RMSE\"], color='coral')\n",
        "axes[1].set_xlabel(\"RMSE\")\n",
        "axes[1].set_title(\"Compara√ß√£o de Modelos - RMSE\")\n",
        "axes[1].grid(axis='x', alpha=0.3)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "S-NUFK5IN8iM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Feature importances\n",
        "importances = best_model.featureImportances.toArray()\n",
        "\n",
        "feature_importance_df = pd.DataFrame({\n",
        "    \"feature\": feature_cols,\n",
        "    \"importance\": importances\n",
        "}).sort_values(\"importance\", ascending=False)\n",
        "\n",
        "# Top 15 features\n",
        "top_features = feature_importance_df.head(15)\n",
        "\n",
        "plt.figure(figsize=(10, 8))\n",
        "plt.barh(top_features[\"feature\"][::-1], top_features[\"importance\"][::-1], color='teal')\n",
        "plt.xlabel(\"Import√¢ncia\")\n",
        "plt.title(\"Top 15 Features Mais Importantes - Random Forest\")\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "print(\"\\nüìä Top 15 Features mais importantes:\")\n",
        "print(top_features.to_string(index=False))\n"
      ],
      "metadata": {
        "id": "YCwbEX9FN9eT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Salvar modelo\n",
        "model_path = \"/content/best_sales_rf_model\"\n",
        "best_model.write().overwrite().save(model_path)\n",
        "\n",
        "# Compactar\n",
        "import shutil\n",
        "shutil.make_archive(\"best_sales_rf_model\", 'zip', model_path)\n",
        "\n",
        "print(\"‚úÖ Modelo salvo e compactado!\")\n",
        "print(f\"   Arquivo: best_sales_rf_model.zip\")\n"
      ],
      "metadata": {
        "id": "YwO_fBthN_lR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q ipywidgets\n",
        "\n",
        "import ipywidgets as widgets\n",
        "from IPython.display import display\n",
        "\n",
        "# Obter listas √∫nicas\n",
        "states_list = [row.state for row in sales_agg.select('state').distinct().collect()]\n",
        "categories_list = [row.category for row in sales_agg.select('category').distinct().collect()]\n",
        "\n",
        "# Widgets\n",
        "state_widget = widgets.Dropdown(options=sorted(states_list), description='Estado:')\n",
        "category_widget = widgets.Dropdown(options=sorted(categories_list), description='Categoria:')\n",
        "year_widget = widgets.IntSlider(value=2018, min=2016, max=2020, description='Ano:')\n",
        "month_widget = widgets.IntSlider(value=6, min=1, max=12, description='M√™s:')\n",
        "predict_button = widgets.Button(description='Fazer Previs√£o', button_style='success')\n",
        "output_widget = widgets.Output()\n",
        "\n",
        "def on_predict_button_clicked(b):\n",
        "    with output_widget:\n",
        "        output_widget.clear_output()\n",
        "\n",
        "        state = state_widget.value\n",
        "        category = category_widget.value\n",
        "        year = year_widget.value\n",
        "        month = month_widget.value\n",
        "\n",
        "        # Buscar dados hist√≥ricos para calcular lags\n",
        "        hist = sales_agg.filter(\n",
        "            (F.col(\"state\") == state) &\n",
        "            (F.col(\"category\") == category)\n",
        "        ).orderBy(\"year\", \"month\").tail(3)\n",
        "\n",
        "        if len(hist) < 3:\n",
        "            print(\"‚ö†Ô∏è Dados hist√≥ricos insuficientes para esta combina√ß√£o\")\n",
        "            return\n",
        "\n",
        "        # Criar features baseadas nos √∫ltimos 3 meses\n",
        "        input_data = {\n",
        "            'year': year,\n",
        "            'month': month,\n",
        "            'quarter': (month - 1) // 3 + 1,\n",
        "            'avg_day_of_week': hist[-1]['avg_day_of_week'],\n",
        "            'num_orders': hist[-1]['num_orders'],\n",
        "            'avg_price': hist[-1]['avg_price'],\n",
        "            'total_freight': hist[-1]['total_freight'],\n",
        "            'unique_orders': hist[-1]['unique_orders'],\n",
        "            'sales_lag_1': hist[-1]['total_sales'],\n",
        "            'sales_lag_2': hist[-2]['total_sales'] if len(hist) > 1 else 0,\n",
        "            'sales_lag_3': hist[-3]['total_sales'] if len(hist) > 2 else 0,\n",
        "            'orders_lag_1': hist[-1]['num_orders'],\n",
        "            'orders_lag_2': hist[-2]['num_orders'] if len(hist) > 1 else 0,\n",
        "            'sales_rolling_mean_3': hist[-1]['sales_rolling_mean_3'],\n",
        "            'orders_rolling_mean_3': hist[-1]['orders_rolling_mean_3'],\n",
        "            'state': state,\n",
        "            'category': category\n",
        "        }\n",
        "\n",
        "        # Criar DataFrame Spark\n",
        "        input_df = spark.createDataFrame([input_data])\n",
        "\n",
        "        # Aplicar transforma√ß√µes\n",
        "        input_indexed = idx_state.fit(input_df).transform(input_df)\n",
        "        input_indexed = idx_category.fit(input_indexed).transform(input_indexed)\n",
        "        input_vec = assembler.transform(input_indexed)\n",
        "        input_scaled = scaler.fit(input_vec).transform(input_vec)\n",
        "\n",
        "        # Fazer previs√£o\n",
        "        prediction_result = best_model.transform(input_scaled)\n",
        "        predicted_sales = prediction_result.select('prediction').first()[0]\n",
        "\n",
        "        print(f\"üìä PREVIS√ÉO DE VENDAS\")\n",
        "        print(f\"   Estado: {state}\")\n",
        "        print(f\"   Categoria: {category}\")\n",
        "        print(f\"   Per√≠odo: {month}/{year}\")\n",
        "        print(f\"   Vendas Previstas: R$ {predicted_sales:,.2f}\")\n",
        "\n",
        "        # Mostrar hist√≥rico\n",
        "        print(f\"\\nüìà Hist√≥rico recente:\")\n",
        "        for i, h in enumerate(hist[-3:], 1):\n",
        "            print(f\"   {h['month']}/{h['year']}: R$ {h['total_sales']:,.2f}\")\n",
        "\n",
        "predict_button.on_click(on_predict_button_clicked)\n",
        "\n",
        "# Exibir interface\n",
        "ui = widgets.VBox([\n",
        "    widgets.HBox([state_widget, category_widget]),\n",
        "    widgets.HBox([year_widget, month_widget]),\n",
        "    predict_button,\n",
        "    output_widget\n",
        "])\n",
        "\n",
        "print('üéØ Use os controles abaixo para fazer previs√µes:')\n",
        "display(ui)\n"
      ],
      "metadata": {
        "id": "iOfCO1TsOAvR"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}